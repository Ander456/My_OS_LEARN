chapter 1
    操作系统简介
chapter 2
    操作系统提供的 中断 异常 系统调用简介 通过这三种方式为多道程序（也就是多进程）提供协作因为CPU实在太快了啊
chapter 3
    内存管理
        * 地址空间&&地址生成：逻辑地址空间的生成是编程序->编译->链接->loader生成的一个连续的地址空间举个例子：高级语言一个函数foo()首先编译然后汇编这个时候函数名变成了地址75，然而我们可能用到了其他库的函数，这就需要链接，就会把不同的需要的文件拼接起来，这个时候前面插入了一段代码，这个时候就会有地址偏移比如偏移了100，此时foo地址变成了175；最后需要进行程序加载重定位，因为程序不一定是从逻辑地址0开始后的，如果是从1000那么foo此时加上偏移就是1175，这个才是我们需要的逻辑地址
        * 逻辑内存和物理内存:物理内存就是实实在在的内存条。逻辑内存也就是我们抽象出来的连续的地址空间
        * 连续内存分配：1. 最先分配分配第一块空闲内存 2. 最优分配 分配大小最合适的 3. 分配空闲内存最大的最差分配。可以通过 压缩式把一些空闲内存压缩或者碎片整理但还是都会产生内碎片和外碎片
        * 非连续内存分配：
            * 分段：针对程序的，我们的程序都可以分配 堆段 栈段 程序数据段 BSS段 text代码段
                * 分段系统中逻辑地址（虚拟地址）由 段号SegmentNum 和 段内地址也就是偏移组成，每个程序设置一个段表
                * 地址变换：通过段号找在段表中找到索引为段号的item然后这个item表项里存放的是物理地址的base基质和limit也就是范围，如果当前段表逻辑地址（段号+偏移）里的偏移是在这个limit范围的也就是没有越级，然后这个Base到Base+limit就是这个段的物理地址空间
            * 分页：通常按照固定的4KB大小把逻辑内存分页形成页表同理物理内存也按照4KB大小对应分帧
                * 同分段来说 分页系统中 一个内存物理地址都由 帧号F和帧内偏移 组成是不是和上面的段号和段内偏移基本差不多。。而逻辑地址呢，举一反三就是每个逻辑页内的逻辑地址也是一个二元组，页号P和页内偏移组成是不是一模一样，只不过就是页来对应帧罢了。
                * 地址变换：同分段，CPU访问逻辑地址先从逻辑地址找到了页号P然后在页表里通过页号P为索引找到了页表项，页表项里存着一些标记标记对应的物理帧否存在啊之类的flag，然后就是存着物理地址的帧号，ojbk我们找到了帧号也就找到了真正的物理地址在哪了。就是这一帧的物理内存基址+我们的帧内偏移（也就是逻辑地址里的页内偏移这俩是相等的）
                * 因为同段表一样每个程序也都会有页表，但是因为现在很多机器都是64位的也就是寻址空间是64位的2的64次方，然后以4kb为一页的页表那么会存在太庞大数量级的数组元素了。。。也就是2的64次方除以2的14次方，也就是2的50次方个条目。基本不可能会有这么大的表，我们为了解决存储问题
                    * 使用TLB来缓存近期访问的页帧转换项，也就是有这么一个表key是页号value是帧号，然后这个TLB是在CPU中的很快，但是存储量很小只能存储最常用的近期的
                    * 用时间来换空间，建立多级页表比如二级页表三级页表甚至5级页表，每一级存着上一层的页号，（有点跳表的意思）这样来形成很多小的页表，不需要的也就不用加到内存来，这样解决存储问题。同时也出现了为了解决多级页表时间复杂度高的反向页表，也就是页表的存储key采用的不是页号p而是帧号f，反过来存储了。因为实际的内存是
        * 虚拟内存
            * 虚拟内存因为内存可能不够所以我们需要使用硬盘辅助来实现虚拟内存来让进程无感知的运行在足够的内存中
            * 虚拟内存技术：
                * 覆盖 同一进程的不同部分（可以简单的理解为不同的Segment)不存在互相调用的情况的时候，可以把硬盘里的某一个Seg覆盖当前内存的一块区域
                * 交换 swapin swapout 不同进程间的，把暂时可以不用的程序swapout到硬盘，把需要用的swapin到内存
                * 虚拟技术 因为上面两点都要求过高，覆盖需要对程序划分不同的块，交换呢需要注意交换时机 交换区的大小（你想要保证程序可以swapout到硬盘肯定得保证硬盘有足够大的交换区）还有就是换回来的重定位问题都需要考虑所以有了虚拟技术可以既像覆盖一样能够把同依程序的不同部分放到内存，也能像交换一样把进程在内存和硬盘之间交换,因为增加了硬盘来辅助可以实现虚拟地址远大于实际物理地址
                * 虚拟技术需要：
                    * 程序的局部性原理
                        * 时间局部性 * 空间局部性
                    * 在分段和分页管理内存的基础上实现（就是因为分段和分页才能实现）
                * 虚拟技术特征：
                    * 结合物理内存提供远大于物理内存的虚拟空间
                    * 部分交换 与交换技术相比粒度更小，交换是不同进程，而这里可以是以分段和分页的形式交换粒度肯定更小了啊
                    * 不连续性：因为swap导致了一些逻辑地址上的不连续（这个不用关心操作系统帮你处理）
                    * 页面替换算法：因为缺页中断我们需要提供算法来实现选择内存中哪个物理页面被置换目的就是为了尽可能的减少页面换进换出次数
                        * 局部页面置换算法:针对一个进程来
                            * 最优页面置换算法：理想情况 置换 将来下次访问等待时间最久的页 （实际无法实现）
                            * 先进先出算法: 系统维护了一个链表当发生缺页中断的时候把链表首部也就是驻留在内存最久的页淘汰swapout然后把需要访问的物理页加入内存中
                            * 最近最久未使用算法：最优的反向根据过去来推算最近最近没有被访问的页面
                            * 最近被使用的算法LRU:链表或者堆栈实现 最近被访问的查下如果有就把它如果没有就直接放到链表头或者堆栈底部，淘汰就淘汰链表尾部或者堆栈顶部的
                            * 时钟页面置换算法：页表项里有一位表示是否被访问过的位，然后用链表将页表连成圆环，指针扫到访问位如果是0表示没被访问过，那么可以直接置换这个页然后同时指针指向下个位置；如果是1表示被访问过，那么此时这个位清0，然后继续往下扫，直到找到访问为是0的（所以可能走一圈哈哈）注意，只有替换页以后指针就会指向下一个了
                            * 二次机会法：页表里还有一位表示dirty位，如果是1就表示这一页是否被写入了内容（也就是内容和原来硬盘上的不一样了)然后判断的时候是结合时钟页面的，通过两位usedbit和dritybity当两位都是0的时候就会swap这页，其实dirtybit就相当于复活甲，能让这个页多一次机会被clock扫。为什么要这么做呢？就是因为如果这个页被写入了内容，那么很可能还会被继续写入，如果我们不给它机会而直接swap出去那么发生缺页的概率就更大了，而dirtybit的作用就是减少被替换的次数保证每次替换前能进行更多次的写入操作
                            * 最不常用算法：当发生缺页中断时，选择访问次数最少的那个页面淘汰
                            * Belady(一个科学家）现象：采用FIFO也就是先进先出的算法的时候，有时候会出现分配的物理页面数增加但是缺页率反而提高而LRU算法并不会。这是为什么呢？因为LRU这种算法是可以保证页面少的是页面多的子集(说实话我也不是很理解这个，我的理解就是当下或者最近使用的很有可能再使用。。概率问题)lru能更好的适应你的局部性程序;Clock类似FIFO算法然后利用bit位模拟LRU
                        * 全局页面置换算法
                            * 如果局部性原理不成立也就是说你的程序并不具备局部性，那么上面的各种局部性页面置换算法就没啥区别了也没什么意义
                            * 工作集working-set 一个进程当前正在使用的逻辑页面的集合，注意了是逻辑页面（肯定啊，哈哈）这个能体现出局部性，比如一段时间内集合内的页面基本都是重复的证明就是局部的来回的
                            * 常驻集 当前的时刻进程实际驻留在内存当中的页面结合，所以可以看出来常驻集就是实际在内存中的而工作集可能有的页在硬盘上这就是区别,同时由于我们知道如果符合局部原理的话我们增加一个进程的物理帧页数也就是提高这个常驻集的大小，那么很大概率的降低缺页中断得发生
                            * 工作集页置换算法：就是给工作集一个固定窗口范围，比如说我们指定工作集合大小为4，那么就会站在整个系统而不是某一个进程的角度去置换页面，随着时间走，窗口不断的滑动但是大小还是保持4，所以滑动过程中窗口外的就可以被置换了
                            * 缺页率页面置换算法：缺页率越高我们越需要改变它的常驻集大小,可以动态的调整常驻集大小。注意是动态的。缺页率 = 缺页次数/内存访问次数
                            * 抖动问题：当前需要的内存很大概率在硬盘上造成了频繁的切换页。这个解释了一个现象，为什么程序开的多的时候电脑会变的卡，因为程序越多，造成内存缺页的概率就越大，如果CPU把大量精力放在页面的换入换出上，肯定就会卡了啊。 

chapter 7                        
    * 进程管理
        * 进程：一个具有一定独立功能的程序在数据集合上的一次动态执行过程
        * 进程包括：
            * 程序的代码
            * 程序处理的数据
            * 程序计数器中的值，只是下一条将要运行的指令
            * 一组通用的寄存器的当前值，堆、栈
            * 一组系统资源，比如打开的文件
        * 进程是动态的 程序是静态的代码集合 进程是一程序的一次在数据集合上的执行
        * 进程的特点：
            * 动态性 可以动态创建结束
            * 并发性 可以被独立调度占用CPU
            * 独立性 不用进程的工作不相互影响（内存管理里的页表就是保证进程独立的重要机制，不同的进程分配不同的页表）嗯~现在看内存管理就很舒服了
            * 制约性 因访问共享数据/资源或者进程间同步而产生制约
        * PCB process control block 保存该进程有关的各种状态信息 进程存在的唯一标识
        * 同一状态的进程其PCB成一条链表；多个状态对应多个不同的链表,各个状态的进程行程不同的链表：比如就绪链表，阻塞链表等
        * 进程生命周期：
            * 创建 运行 等待 唤醒 结束
            * 进程只能自己阻塞自己来等待，因为别人也不知道你需不需要等待
            * 进程只能靠其他进程或者操作系统来唤醒
            * 进程可以被操作系统或者其他进程创建
            * 进程可以自愿的正常/错误退出 然后也可能会因为致命错误强制被结束 或者强制的被其他进程所杀
            * 运行态 阻塞态 就绪态
        * 进程挂起
            * 阻塞挂起状态: 进程在外存并等待某事件的出现
            * 就绪挂起状态: 进程在外存但只要进入内存即可运行(其实就是挂起又分了下状态阻塞就是在等待就绪就是已经完事了准备好run了，但是这个时候还是处于挂起状态的)
            * 挂起：把一个进程从内存转到外存
                * 阻塞到阻塞挂起：没有进程处于就绪态状态或就绪进程要求更多资源时会进行这种转换以提交新进程或运行就绪进程
                * 就绪到就绪挂起：当有高优先级阻塞进程和低优先就绪进程时，系统会选择挂起低优先级就绪进程
                * 运行到就绪挂起：对抢先式分时系统当有高优先级阻塞挂起进程因事件出现而进入就绪挂起时，系统可能会吧运行进程转到就绪挂起状态(也就是准备挂起状态)
            * 在外存时的状态转换：
                * 阻塞挂起到就绪挂起：当有阻塞挂起进程因事件出现系统会把阻塞挂起进程转换为就绪挂起进程（看上面的就绪挂起状态的解释就好）
            * 解挂/激活：把一个进程从外存转到内存
                * 就绪挂起到就绪：没有就绪进程或挂起的就绪进程优先级高于就绪进程时，会进行这种转换把进程从外存转到内存
                * 阻塞挂起到阻塞：当一个进程释放足够内存时，系统会把一个高优先阻塞挂起进程转换为阻塞进程（系统认为会很快出现所等待的事件）注意了，这里进程状态只是变为了阻塞状态并不是挂起，要分清楚阻塞和挂起，挂起就要把进程从内存转到外存了,而阻塞只是变为了等待状态还在内存中
        * 状态队列
            * 操作系统维护队列
            * 不同状态进入不同队列
            * 状态变换从原队列脱离进入另一个队列
    * 线程管理
        * 线程：进程当中的一条执行流程（就是程序的执行路径。。）进程就是线程的资源平台，线程就是进程的一条执行路径
        * 进程 =  线程 + 资源管理
        * 一个线程崩溃其所属进程的所有线程都崩溃
        * 适用性：
            * 线程：强调性能的地方更多的使用线程
            * 进程：强调安全性不容易crash的更多的使用进程 比如浏览器chrome就是多进程方式
        * 进程是资源分配单位 线程是CPU调度的单位
        * 多线程 每个线程都有 自己独立的 stack和寄存器s
        * 线程实现方式：
            * 用户线程：用户态的线程库管理
            * 内核线程：内核管理（相当于内核的分身）通常一个CPU核心对应一个内核线程，多核的就每个对应一个内核线程,这些都是我们操作系统的内核来管理的，所以说有点分身的意思
            * 轻量级进程
        * 用户线程和内核线程的对应关系：
            * 多对一 一对一 多对多
        * 用户线程
            * 优点
                * 由于线程维护由相应的库函数来完成不需要内核参与所以可以在不支持多线程的操作系统上跑
                * 线程的TCB数据块由函数库自己来维护
                * 线程切换也是线程库来完成的无序用户态/内核态的切换所以速度很快
                * 允许每个进程拥有自己独立的线程调度算法
            * 缺点
                * 一个线程发起系统调用而阻塞，因为操作系统不知道用户线程的存在，所以操作系统会挂起整个进程，这个时候整个进程都在等待
                * 当一个线程执行后除非主动交出CPU使用权，否则其他所有线程都无法运行
                * 由于时间片是分配给进程的，所以多线程执行时每个线程得到的时间片就更少了执行会比较慢
            * POSIX Pthreads, Match C threads, Solairs threads 支持用户线程
        * 内核线程
            * 内核来维护进程和线程的上下文信息PCB和TCB
            * 创建终止切换都通过系统调用/内核函数的方式来进行，由于内核来完成因此系统开销较大(因为内核做了这件事肯定就会放下那件事)
            * 一个进程中如果某个内核线程发起系统调用而被阻塞，并不会影响其他内核线程的运行
            * 时间片分给线程，多线程的进程获得更多的CPU时间
            * windowNT/XP 支持 内核线程
        * 轻量级进程(LightWeight Process LWP)
            * Solaris/Linux 支持
            * 它是内核支持的用户线程，一个进程可以有一个或多个轻量级进程，每个轻量级进程有一个单独的内核线程来支持(一对一)
    * 上下文切换
        * 停止当前运行进程并且调度其他进程
        * 停止当前进程把state也就是寄存器CPU状态等进程的信息全都保存在进程控制块PCB的一个地方，然后把另一个进程的PCB里保存的相关信息恢复到相关寄存器等位置然后开始执行;这些实现一般都是汇编来实现的保证高效
    * 进程控制
        * 创建：
            * fork() 系统调用 创建子进程；复制父进程所有的变量和内存(真实的地址空间物理地址)以及父进程的CPU寄存器；（这里就是一个性能开销比较大的地方，需要把进程的各segment段都copy到内存的另一个地方）
            * 子进程的fork返回0，父进程的fork返回子进程的标识符,但是如果<0那么fork失败了；fork返回值方便后续使用
        * 加载和执行进程
            * exec() 加载程序取代当前运行的进程;注意执行了exec()那么进程的代码段、堆、栈都会被覆盖重写
            * 99%的情况我们fork()之后调用exec()因为单纯的fork只是copy了内存并没有其他作用，我们需要exec()来执行程序，但是我们执行了exec()就会把复制出来的内存里的数据段代码段等全部覆盖掉;
            * 优化方案
                * vfork： 虚fork系统调用 fork的时候只复制一小部分
                * Copy on Write： fork的时候单单copy父进程的页表，这样都父子进程的页表都指向了同一块地址空间。当我们父进程或子进程对某一个地址单元进行写操作的时候会出发一个异常，然后才会把触发异常的页copy为2份，同样物理帧地址也copy
        * 等待和终止进程
            * wait() 系统调用是被父进程用来等待子进程的结束的
            * 僵尸进程： exit()之后 wait()返回之前这个阶段的进程就称为僵尸进程

chapter 8
    * 进程调度
        * 非抢占式的：调度程序必须等代事件结束，这个效率不高，比如进程如果处于阻塞了，由于这个进程没有执行完毕，后一个进程没法被调度
        * 抢占式
            * 调度程序在中断被响应后执行
            * 当前的程序从运行切换到就绪，或者一个进程从等待切换到就绪
            * 当前运行的程序可以被换出
        * CPU利用率：cpu处于繁忙状态所占时间的百分比
        * 吞吐量：在单位时间内完成的进程(task)数量
        * 周转时间：一个进程从初始化到结束包括所有等待的时间
        * 等待时间：进程在就绪队列中的总时间
        * 响应时间：从一个请求被提交到产生第一次响应所花费的总时间 比如按键盘到响应这个时间
    * 调度算法：
        * FCFS 先来先服务
        * SPN/SRT 短进程优先，优先剩余时间短的,SNF和SRT区别是抢占与否。就是运行中如果还有一个剩余时间更短的则调度他
        * HPRN 最高响应比优先
        * Round Robin 轮询
        * Mutilevel Feedback Queues 多级反馈队列
        * Fair Share Scheduling 公平共享调度

chapter 9
    * c语言的 new_pid = next_pid++; 翻译成汇编就是
        * LOAD next_pid Reg1
        * SOTRE Reg1 new_pid
        * INC Reg1
        * Store Reg1 next_pid
        既然是四条执行指令。。肯定就有可能会因为操作系统调度程序导致被打断执行从而执行结果并不确定
    * Race Condition竞态条件
        * 避免不确定性
            * AtomicOperation原子操作
                * 该执行成功结束
                * 或者根本没有执行
                * 并且不应该发现任何部分执行的状态
            * 实际操作往往不是原子的
    * 临界区 进程中的一段需要访问共享资源并且当另一个进程处于响应代码区域时便不会被执行的代码区域，注意临界区是代码区域
    * 互斥 当一个进程处于临界区并访问共享资源时，没有其他进程会处于临界区并且访问任何相同的共享资源
    * 死锁 两个或以上进程，在相互等待完成特定任务，而最终没法将自身任务进行下去
    * 饥饿 一个可执行的进程被调度器持续忽略，以至于虽然处于可执行状态却不被执行
    * 处理临界区竞态的方法
        * 禁用硬件中断：没有中断也就没有上下文切换，但是会也就没有了并发
        * 基于软件的解决方法：Peteson算法 flag[i] = TRUE; turn =j; (i是本进程 j是另外一个进程) while(flag[j] && turn == j) 来表示是否进去临界区 
        * 更高级的额抽象：
            * 硬件提供了一些原语：中断禁用；原则操作(test_and_set)等
            * 操作系统提供更高级的编程抽象： 锁；信号量
            * 锁的实现需要硬件支持，常用的三中硬件支持的方法是：禁用中断，软件方法，原子操作（最优方案）
    
chapter 10 
    * 信号量
        * 信号量是整数Sem，整型
        * 初始化完成后唯一改变信号量的方法就是通过P() V() 原子操作
        * P操作让Sem -1  如果Sem <0 等待(挂起) 否则继续
        * V操作让Sem +1  如果Sem <=0 唤醒一个等待的进程 (为啥是<=0因为如果是-1+1了等于0表明上一个进程或线程是阻塞的了，我们这边给它+1也还是0)
        * 简单理解就是 如果信号<=0 说明还有进程阻塞 可以执行唤醒操作,Sem可以用来表示一个可用量的信号，可用量如果<0那么肯定得阻塞等会了
        * 信号量可以用在2个方面
            * 互斥
            * 条件同步（调度约束--一个线程等待另一个线程的事件发生）
        * 生产者-消费者模型
            * 在任何一个时间只能由一个线程操作缓冲区（互斥）
            * 当缓冲区为空，消费者必须等待生产者（调度/同步约束）
            * 当缓冲区满了，生产者必须等待消费者（调度/同步约束）
            * 需要三个信号量就可实现上面的模型
                * mutex互斥信号量可以初值为1
                * fullBuffers 初值为0 size最大为n 表示缓冲区有多少货被占用的是多少
                * emptyBuffers 初值为n 表示缓冲区没被占用的空着的块是多少
        * 信号量的实现：
            * P操作后如果sem<0那么把当前thread的TBC数据块放到一个等待队列
            * V操作后如果sem<=0那么从等待队列中拿出一个thread的TBC数据块然后唤醒(和进程的队列一样其实)
    * 管程
        * 包含了一系列的共享变量以及针对这些变量的操作的函数的一个模块叫做管程
            * 一个锁：指定临界区
            * 0或者多个条件变量：等待/通知信号量用于管理并发访问共享数据
            * 注意这里的condition和上面的信号量不是一个东西表示的概念也不同虽然都是整形的值
chapter 12  
    * 所有的数据块datablock都抽象成了file，一个文件file可以有一个或者多个数据块（也就是磁盘上我们保存的数据）来组成
    * 文件描述符
        * 操作系统为每个进程维护一个打开文件表
        * 一个打开文件描述符是这个表中的引用 [文件描述符(一个int值)] = {一个对应的表项}
    * 虚拟文件系统
        * 其实你看内存管理也有虚拟管理技术。所以文件系统也一样，就是为了抽象管理不同的具体实现物理然后来提供通用的抽象接口的
        * 卷控制块superblock:每个文件系统一个 文件系统的详细信息 块，块大小、空余块、计数/指针等
        * 文件控制块inode:每个文件一个 文件详细信息 许可、拥有者、大小、数据库位置等
        * 目录节点destry:每个目录项一个(可以管理目录/文件) 将目录项数据结构及树形布局编码成树形数据结构 指向文件控制块、父节点、项目列表等










